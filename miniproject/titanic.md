
# 모델 학습 시 고려사항 가이드

 모델이 우수한 성능을 낸다고 하더라도, 그 이유를 분석가/사이언티스트가 이해하고 있지 못한다면 결코 의미있지 않습니다. 코드를 짜는 시간보다 고민하는 데에 더 많은 시간을 할애하셨으면 합니다. 또 결과를 통해 증명하기보다 본인의 논리를 믿고 따르는 습관을 들이면 좋겠습니다. 예상과 다르다면 다시 학습해가면 됩니다.

 모든 부분에 힘을 주실 필요가 없습니다. 


------------
https://drive.google.com/file/d/1xB0Z1PPKopxaT76R1sHggOkILcvi_Wad/view?usp=sharing
### 개괄
1. 범주형 데이터셋(이진)
2. 주어진 컬럼들을 이용하여 타깃변수 "survived"의 값을 예측하면 된다.


--------------
모델을 학습할 때는 다양한 요소를 고려해야 합니다. 이는 데이터의 전처리부터 모델의 선택과 평가에 이르기까지 여러 단계에 걸쳐 영향을 미칩니다. 아래는 주요한 요소들을 설명합니다.

1. 결측치 처리
> 🧞‍♀️ 시각화 등으로 결측치를 확인해주세요. 각 열의 결측치를 대체한 방법과 왜 그 방법을 사용했는지에 관하여 논리적으로 서술해주세요.
A. 결측치 확인: ``` ori_train.isnull().sum() ``` ```ori_train.info()```
  drop을 하는 방법, fill을 하는 방법 등... 컬럼의 특성에 맞게 선택?
> 정규분포를 띄고 있기 때문에 드랍보다는 채워넣는게 성능이 더 좋을 것 같다. (버려지는 데이터가 적으니까)
> 채워넣는다면 그냥 중간값을 넣는 것이 무난해 보인다.
> 아니면 빈도에(표준편차와 평균에 맞게) 맞춰서 각각 다른 값을 채워넣는다면 어떻게 될까? 같은 값을 다 넣어버리면 그래프의 모양이 달라져버리니깐


3. 데이터 스케일링

> 🧞‍♀️ 해당 데이터의 정규화 필요성에 대하여 논의해주세요. 해당 분포를 모델링에 적합한 형태로 변환하기 위해 사용한 스케일링 방식에 대해 설명해주세요.
> (ex. MinMax 스케일링은 이상치에 관하여 민감하므로, 그렇지 않은 ~ 방법을 사용했습니다.)
A. 연속형 변수에 대하여 이상치 처리를 완료하였으므로, MinMax 스케일링을 사용해도 괜찮다고 생각하여 MinMax 스케일링을 사용하였습니다.

5. 이상치(Outliers)
이상치 처리: 이상치는 모델에 부정적인 영향을 줄 수 있기 때문에 이를 식별하고 처리하는 것이 중요합니다. 이상치를 제거하거나, 다른 값으로 대체(예: 중앙값)하는 방법이 있습니다. 이상치가 반드시 잘못된 것은 아니므로 주의해야 합니다.

> 🧞‍♀️ 이상치를 처리하였나요? 어떤 기준으로 이상치를 판단하였나요?
A. fare 컬럼은 비정규분포를 띄고 극단적 이상치가 많아 iqr로 이상치를 처리하였습니다.
> Age 컬럼은 정규분포를 띄므로 z스코어 3 이상의 값을 이상치로 처리하였습니다.

7. 데이터 분할
훈련/검증/테스트 데이터 분할: 데이터셋을 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가합니다. 일반적으로 70-80%를 훈련 데이터로 사용하고, 나머지를 검증과 테스트 데이터로 사용합니다.

> 🧞‍♀️ 데이터 분할 방법 중 K-Fold Cross-Validation과 Stratified K-fold Cross Validation에 대해 공부해보세요. 최종적으로 어떤 방법을 사용했는지, 왜 사용했는지에 대해 서술해주세요.
A. K폴드 교차검증이란 데이터를 K개로 나누어 K번 검증하는 검증방식이다. 층화 K폴드 검증이란 타깃값의 분포가 불균형할 때, 분할된 데이터셋 내의 타깃값의 분포를 일정하게 유지하여 분할하는 검증방식이다.
> 층화 K폴드 방식을 사용하였는데, survived 값의 분포가 불균형하기 때문에 층화 K폴드 방식이 유리하다고 생각했다.

9. 모델 평가
평가 지표 선택: 회귀 문제에서는 MSE, MAE, R², 분류 문제에서는 정확도, 정밀도, 재현율, F1-score 등을 사용하여 모델 성능을 평가합니다.
교차 검증(Cross-Validation): 데이터를 여러 번 분할하여 모델을 평가하는 방법입니다. 이를 통해 모델의 일반화 성능을 더 잘 평가할 수 있습니다.

> 평가 지표의 종류에 대해 공부해보세요. 
A. 

-----
공통 질문

1. 그 외, 모델의 성능을 높이기 위하여 기여한 부분에 대해 설명해주세요.
A. 랜덤포레스트 모델이 아닌 xgboost 모델을 사용하여 더 좋은 결과를 만들었습니다. XGBoost는 다양한 최적화와 정규화 기법을 통해 과적합을 방지하면서도 더 정확한 예측을 할 수 있습니다. 또한, 속도가 더 빠르고 불균형 데이터 처리에서도 우수한 성능을 보입니다. 이외에도, XGBoost는 조기 종료 기능을 통해 모델 훈련 중 과적합을 방지할 수 있어 전체적으로 랜덤포레스트보다 더 강력한 모델을 생성할 수 있습니다.

2. 결과가 어땠나요? 그리고 왜 그런 결과가 나왔다고 생각하시나요?
A. 캐글 제출 결과 Score: 0.73205로 그렇게 좋은 점수가 나온 것 같지는 않습니다. 아마 결측치를 처리하는 과정에 문제가 있었다고 생각됩니다. 나이 관련해서 결측치에 전부 평균값을 넣었는데, 그 부분이 조금 아쉬웠던 것 같습니다. 나이의 분포에 대해서 고려하여 결측치를 채워 넣었다면 더 좋은 결과가 나왔을 것 같습니다.
또한 스케일링을 하는 과정에서도 minmax 스케일링보다 정규화를 하는 것이 더 좋은 결과가 나올 수도 있었다고 생각합니다.

3. 시간이 더 있었다면 어떤 노력을 더 해봤을 것 같나요?
A. 앞에서 말했던 결측치 처리하는 방법이나 스케일링을 하는 방법에 있어서 더 다양한 시도를 해보고 결과를 비교했다면 더 좋은 결과가 있었을 것 같아서 아쉽습니다. 또한 다른 머신러닝 모델에 대하여 더 공부하고 각각의 특징을 이해해서 상황에 맞는 모델을 적용할 수 있으면 더 좋을 것 같습니다.

